Ethical_LLM_System/
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ MaliciousQueries.csv
â”‚
â”œâ”€â”€ ğŸ“ experiments/
â”‚   â”œâ”€â”€ run_experiment.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ results/
â”‚   â”‚   â”œâ”€â”€ finbert_results.json
â”‚   â”‚   â”œâ”€â”€ hatebert_results.json
â”‚   â”‚   â”œâ”€â”€ sentibert_results.json
â”‚   â”‚   â””â”€â”€ ensemble_results.json
â”‚
â”œâ”€â”€ ğŸ“ application/
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”œâ”€â”€ ethical_pipeline.py
â”‚   â”œâ”€â”€ ethical_alternatives.py
â”‚   â””â”€â”€ llm_generator.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .env                (optional â€“ API keys, local only)
â””â”€â”€ venv/               (local virtual environment â€“ NOT shared)
